{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NYC Taxi Trip Duration Prediction â€“ Modeling\n",
        "\n",
        "This notebook covers the modeling phase of the project:\n",
        "- Load and preprocess data  \n",
        "- Train baseline models  \n",
        "- Evaluate candidate models (tree-based ensembles)  \n",
        "- Save results for tracking  \n",
        "- Train and save final model  \n",
        "- Test final model on hold-out dataset  \n"
      ],
      "metadata": {
        "id": "SxqgWwHkneA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup and Install Dependencies\n",
        "We install specialized libraries (XGBoost, LightGBM, CatBoost) and import required packages.\n"
      ],
      "metadata": {
        "id": "m7Lr46vpnjSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost\n",
        "!pip install lightgbm\n",
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tB_AcqoFHKZr",
        "outputId": "4ea1beb2-ac53-43ed-e64f-69d8a8ac87bc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightgbm) (1.16.2)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Mount Drive and Clone Repository\n",
        "We mount Google Drive for data storage and clone the project repository for preprocessing functions.\n"
      ],
      "metadata": {
        "id": "5CWcn9mynmwk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qu6uinGFjEa",
        "outputId": "87200a1e-22e8-429a-818b-70f166e1c4ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#models\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "\n",
        "#mount data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%matplotlib inline\n",
        "\n",
        "#disable warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import preprocessing functions"
      ],
      "metadata": {
        "id": "AVG25wBzIDOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Eng-Moaz/NYC-Taxi-Trip-Duration.git\n",
        "%cd NYC-Taxi-Trip-Duration\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13eW0ua5HxII",
        "outputId": "be3f36e1-e02e-4d8b-b7ea-ffa88ea07ebb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NYC-Taxi-Trip-Duration'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 48 (delta 9), reused 48 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (48/48), 730.16 KiB | 2.92 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "/content/NYC-Taxi-Trip-Duration/NYC-Taxi-Trip-Duration/NYC-Taxi-Trip-Duration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('src')\n",
        "from preprocessing import preprocess"
      ],
      "metadata": {
        "id": "iJqydqr8IAZa"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data Loading and Preprocessing\n",
        "We load train, validation, and sample splits from Drive, then apply preprocessing functions from `preprocessing.py`.\n"
      ],
      "metadata": {
        "id": "evM7_Y_hI2xK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/Projects/NYC trip duration/split/train.csv')\n",
        "val = pd.read_csv('/content/drive/MyDrive/Projects/NYC trip duration/split/val.csv')\n",
        "train_sample = pd.read_csv('/content/drive/MyDrive/Projects/NYC trip duration/split_sample/train.csv')\n",
        "val_sample = pd.read_csv('/content/drive/MyDrive/Projects/NYC trip duration/split_sample/val.csv')\n",
        "train , val = preprocess(train) , preprocess(val)\n",
        "train_sample , val_sample = preprocess(train_sample) , preprocess(val_sample)"
      ],
      "metadata": {
        "id": "7gGGG1X3IM8V"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X , train_y = train.drop('trip_duration_transformed', axis=1) , train['trip_duration_transformed']\n",
        "val_X , val_y = val.drop('trip_duration_transformed', axis=1) , val['trip_duration_transformed']\n",
        "train_sample_X , train_sample_y = train_sample.drop('trip_duration_transformed', axis=1) , train_sample['trip_duration_transformed']\n",
        "val_sample_X , val_sample_y = val_sample.drop('trip_duration_transformed', axis=1) , val_sample['trip_duration_transformed']"
      ],
      "metadata": {
        "id": "y0s24MwtLBb5"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Project Structure for Saving Results\n",
        "We create folders for storing model results:\n",
        "- baselines/ â†’ Simple models for comparison  \n",
        "- candidates/ â†’ Advanced ensemble models  \n",
        "- final/ â†’ Best chosen model and test results  \n"
      ],
      "metadata": {
        "id": "yzqrTS0pJ0t1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "for folder in [\"results/baselines\", \"results/candidates\", \"results/final\"]:\n",
        "    os.makedirs(folder, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "f5xlCPjEImd4"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Helper Functions\n",
        "- `save_results()` â†’ saves results as JSON  \n",
        "- `evaluate_model()` â†’ trains model and calculates metrics (MAE, RMSE, RÂ²)\n"
      ],
      "metadata": {
        "id": "F-7Tqc_Mn17z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_results(results: dict, filepath: str):\n",
        "    \"\"\"\n",
        "    Save model results dictionary as JSON.\n",
        "    \"\"\"\n",
        "    with open(filepath, \"w\") as f:\n",
        "        json.dump(results, f, indent=4)\n"
      ],
      "metadata": {
        "id": "WoPFtmWEJ_y0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_train, y_train, X_val, y_val):\n",
        "    \"\"\"\n",
        "    Fit model, predict, and return metrics.\n",
        "    \"\"\"\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_val)\n",
        "\n",
        "    results = {\n",
        "        \"params\": model.get_params(),\n",
        "        \"MAE\": mean_absolute_error(y_val, preds),\n",
        "        \"RMSE\": np.sqrt(mean_squared_error(y_val, preds)),\n",
        "        \"R2\": r2_score(y_val, preds)\n",
        "    }\n",
        "    return results"
      ],
      "metadata": {
        "id": "NRoJW2f-K1ah"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Baseline Models\n",
        "We start with simple regression models on sample sets:\n",
        "- Linear Regression  \n",
        "- Ridge Regression  \n",
        "- Lasso Regression  \n",
        "- Random Forest (default settings)  \n",
        "\n",
        "These act as a baseline to judge more complex models.\n"
      ],
      "metadata": {
        "id": "Uu9voSsdRrEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_models = {\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "    \"Ridge\": Ridge(),\n",
        "    \"Lasso\": Lasso(),\n",
        "    \"RandomForest_Default\": RandomForestRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "baseline_results = {}\n",
        "\n",
        "for name, model in baseline_models.items():\n",
        "    metrics = evaluate_model(model, train_sample_X, train_sample_y, val_sample_X, val_sample_y)\n",
        "    baseline_results[name] = metrics\n",
        "    print(f\"{name}: {metrics}\")\n",
        "\n",
        "# Save to results\n",
        "save_results(baseline_results, \"/content/results/baselines/baseline_results.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn7Dh9chLRBK",
        "outputId": "1cbc429c-c3bf-4644-e8a2-06b02a6db58e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression: {'params': {'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False}, 'MAE': 0.2997796099286002, 'RMSE': np.float64(0.41291303746294544), 'R2': 0.6826770493804539}\n",
            "Ridge: {'params': {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, 'MAE': 0.30007437798781095, 'RMSE': np.float64(0.4142042718476044), 'R2': 0.6806893235353795}\n",
            "Lasso: {'params': {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, 'MAE': 0.42822719854458685, 'RMSE': np.float64(0.5473508799009009), 'R2': 0.4424087708432711}\n",
            "RandomForest_Default: {'params': {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}, 'MAE': 0.02110909163130246, 'RMSE': np.float64(0.04446393483969027), 'R2': 0.9963204045041462}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Candidate Models\n",
        "We train stronger tree-based models:\n",
        "- Gradient Boosting  \n",
        "- XGBoost  \n",
        "- LightGBM  \n",
        "- CatBoost  \n",
        "\n",
        "Both on sample data (quick tests) and full data (final evaluation).\n"
      ],
      "metadata": {
        "id": "Jra8HebQoGES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "results_sample = {}\n",
        "\n",
        "models = {\n",
        "    #\"GradientBoosting\": GradientBoostingRegressor(n_estimators=200, max_depth=6, random_state=42),\n",
        "    \"XGBoost\": XGBRegressor(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42, n_jobs=-1),\n",
        "    \"LightGBM\": LGBMRegressor(n_estimators=200, max_depth=-1, learning_rate=0.1, random_state=42, n_jobs=-1),\n",
        "    \"CatBoost\": CatBoostRegressor(n_estimators=200, depth=6, learning_rate=0.1, random_state=42, verbose=0)\n",
        "}\n",
        "\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    results[name] = evaluate_model(model, train_X, train_y, val_X, val_y)\n",
        "    results_sample[name] = evaluate_model(model, train_sample_X, train_sample_y, val_sample_X, val_sample_y)\n",
        "    print(f\"Done {name}...\")\n",
        "    metrics = {k: results[name][k] for k in [\"MAE\", \"RMSE\", \"R2\"]}\n",
        "    print(metrics)\n",
        "\n",
        "\n",
        "# Save to results\n",
        "save_results(results, \"/content/results/candidates/candidate_results.json\")\n",
        "save_results(results_sample, \"/content/results/candidates/candidate_results_sample.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NMaboU0Lo6s",
        "outputId": "ab547df3-f260-41b6-f51a-9fd7f737bddc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training XGBoost...\n",
            "Done XGBoost...\n",
            "{'MAE': 0.010463517162666554, 'RMSE': np.float64(0.016340910921777852), 'R2': 0.9994511773619413}\n",
            "\n",
            "Training LightGBM...\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.169042 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2958\n",
            "[LightGBM] [Info] Number of data points in the train set: 959130, number of used features: 24\n",
            "[LightGBM] [Info] Start training from score 6.450472\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2958\n",
            "[LightGBM] [Info] Number of data points in the train set: 4782, number of used features: 24\n",
            "[LightGBM] [Info] Start training from score 6.431870\n",
            "Done LightGBM...\n",
            "{'MAE': 0.012901100295933611, 'RMSE': np.float64(0.018962946604024634), 'R2': 0.9992609205342038}\n",
            "\n",
            "Training CatBoost...\n",
            "Done CatBoost...\n",
            "{'MAE': 0.013217081113801547, 'RMSE': np.float64(0.0198744694328552), 'R2': 0.999188159750334}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Model Selection\n",
        "- Based on validation scores (MAE, RMSE, RÂ²), we choose XGBoost as the final model.\n",
        "- Also I don't think we need hyperparameter tuning since the scores are almost perfect"
      ],
      "metadata": {
        "id": "9QIj8F7JeC_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "final_model = XGBRegressor(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42, n_jobs=-1)\n",
        "final_model.fit(train_X, train_y)\n",
        "joblib.dump(final_model, \"/content/results/final/final_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie0l-L7mTk51",
        "outputId": "1dde9395-9314-4c76-8462-1c4539e7ec9d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/results/final/final_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/Projects/NYC trip duration/split/test.csv')\n",
        "test = preprocess(test)\n",
        "test_X = test.drop('trip_duration_transformed', axis=1)\n",
        "test_y = test['trip_duration_transformed']"
      ],
      "metadata": {
        "id": "LBFCZwC_hp_C"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Final Testing\n",
        "We load the saved model, test on the hold-out test set, and record final metrics.\n"
      ],
      "metadata": {
        "id": "xYhy7Mc0ouUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = joblib.load(\"/content/results/final/final_model.pkl\")\n",
        "y_preds = model.predict(test_X)\n",
        "results = {\n",
        "        \"MAE\": mean_absolute_error(test_y, y_preds),\n",
        "        \"RMSE\": np.sqrt(mean_squared_error(test_y, y_preds)),\n",
        "        \"R2\": r2_score(test_y, y_preds)\n",
        "    }\n",
        "print(results)\n",
        "save_results(results, \"/content/results/final/testing_results.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReARLYFIhDv6",
        "outputId": "109e8dac-3290-41c5-f220-8f10229a8010"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'MAE': 0.010557512258037189, 'RMSE': np.float64(0.016497358692916356), 'R2': 0.9994408524418551}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1LRgGhysiXQg"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}